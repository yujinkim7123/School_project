{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_full.reshape(X_train_full.shape[0], 28,28,1).astype('float32')\n",
    "X_train = X_train/255.0\n",
    "y_train = y_train_full.astype('float32')\n",
    "y_train = keras.utils.to_categorical(y_train_full, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    leaky_relu = tf.nn.leaky_relu\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Conv2D(34, (3, 3), activation= \"relu\", padding=\"same\", input_shape=[28, 28, 1]))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3),activation= \"relu\", padding=\"same\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation= \"relu\",padding=\"same\"))\n",
    "    model.add(keras.layers.Conv2D(256, (3, 3), activation= \"relu\",padding=\"valid\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(256, activation= leaky_relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(256, activation= leaky_relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "     \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n",
      "processing fold # 4\n",
      "processing fold # 5\n",
      "processing fold # 6\n",
      "processing fold # 7\n",
      "processing fold # 8\n",
      "processing fold # 9\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_val = len(X_train) // k\n",
    "num_epochs = 50\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    X_val = X_train[i * num_val: (i + 1) * num_val]\n",
    "    Y_val = y_train[i * num_val: (i + 1) * num_val]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    X_train_part = np.concatenate(\n",
    "        [X_train[:i * num_val],\n",
    "         X_train[(i + 1) * num_val:]],\n",
    "        axis=0)\n",
    "    Y_train_part = np.concatenate(\n",
    "        [y_train[:i * num_val],\n",
    "         y_train[(i + 1) * num_val:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(X_train_part, Y_train_part,epochs=num_epochs, batch_size=500, verbose=0)\n",
    "    # Evaluate the model on the validation data \n",
    "    val_loss, val_acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    all_scores.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94255"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
