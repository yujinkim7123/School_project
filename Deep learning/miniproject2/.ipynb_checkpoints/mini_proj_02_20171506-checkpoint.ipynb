{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "train = pd.read_csv('acc_train_shuff.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.drop(\"Activity\", axis=1) # drop labels for training set\n",
    "train_data = train_data.drop(\"subject\", axis=1)\n",
    "train_target= train[\"Activity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y_train=encoder.fit_transform(train_target)\n",
    "y_train=pd.get_dummies(y_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=None)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "explained_variance=pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.06917034e-01, 6.56928728e-02, 2.80201500e-02, 2.49949977e-02,\n",
       "       1.88492934e-02, 1.72270906e-02, 1.36882999e-02, 1.20240719e-02,\n",
       "       9.96605995e-03, 9.63400771e-03, 8.59090998e-03, 7.99123948e-03,\n",
       "       7.66606180e-03, 6.47627347e-03, 6.33054913e-03, 5.98740407e-03,\n",
       "       5.86337729e-03, 5.74388078e-03, 5.67200764e-03, 5.26377598e-03,\n",
       "       4.99744876e-03, 4.87639156e-03, 4.82750180e-03, 4.68242333e-03,\n",
       "       4.50609730e-03, 4.22370610e-03, 4.17756221e-03, 4.06574228e-03,\n",
       "       3.90772057e-03, 3.86612070e-03, 3.65789908e-03, 3.53997127e-03,\n",
       "       3.49996523e-03, 3.36688241e-03, 3.31392612e-03, 3.27692614e-03,\n",
       "       3.21282329e-03, 2.95100825e-03, 2.87871517e-03, 2.84731010e-03,\n",
       "       2.71970799e-03, 2.65183896e-03, 2.62941245e-03, 2.58629711e-03,\n",
       "       2.49233733e-03, 2.46522326e-03, 2.40333884e-03, 2.36775833e-03,\n",
       "       2.32859436e-03, 2.27364925e-03, 2.21323923e-03, 2.14833500e-03,\n",
       "       2.07340296e-03, 2.02773682e-03, 1.99490692e-03, 1.98733568e-03,\n",
       "       1.94040854e-03, 1.90783532e-03, 1.88658672e-03, 1.85889025e-03,\n",
       "       1.81609113e-03, 1.77561524e-03, 1.75875419e-03, 1.73059835e-03,\n",
       "       1.70950656e-03, 1.70179345e-03, 1.66340721e-03, 1.62990173e-03,\n",
       "       1.58658719e-03, 1.57299030e-03, 1.54055024e-03, 1.52659823e-03,\n",
       "       1.47951846e-03, 1.46806850e-03, 1.45772877e-03, 1.44394326e-03,\n",
       "       1.38929943e-03, 1.36253940e-03, 1.34732933e-03, 1.32885565e-03,\n",
       "       1.31801511e-03, 1.30184244e-03, 1.28427458e-03, 1.24802276e-03,\n",
       "       1.23515841e-03, 1.21555624e-03, 1.19131322e-03, 1.17294935e-03,\n",
       "       1.16452483e-03, 1.14208417e-03, 1.12899885e-03, 1.09688641e-03,\n",
       "       1.08971210e-03, 1.07252408e-03, 1.04561989e-03, 1.02236748e-03,\n",
       "       1.01579959e-03, 1.00533468e-03, 9.79055036e-04, 9.62927284e-04,\n",
       "       9.35777094e-04, 9.19903679e-04, 9.10817705e-04, 8.94166630e-04,\n",
       "       8.84648507e-04, 8.70494629e-04, 8.67407791e-04, 8.54375257e-04,\n",
       "       8.27170435e-04, 8.26070524e-04, 8.10324443e-04, 8.02495759e-04,\n",
       "       7.81128204e-04, 7.71370531e-04, 7.53391897e-04, 7.49156091e-04,\n",
       "       7.21964518e-04, 7.15833374e-04, 7.07643885e-04, 6.90592270e-04,\n",
       "       6.76163914e-04, 6.62281927e-04, 6.49077674e-04, 6.36386759e-04,\n",
       "       6.26043388e-04, 6.19501010e-04, 6.14135651e-04, 6.00516431e-04,\n",
       "       5.95171663e-04, 5.79511886e-04, 5.73557438e-04, 5.62438210e-04,\n",
       "       5.56479623e-04, 5.43688613e-04, 5.38153859e-04, 5.28238400e-04,\n",
       "       5.23900591e-04, 5.11603684e-04, 5.03964649e-04, 5.01326726e-04,\n",
       "       4.87783786e-04, 4.81356899e-04, 4.73762135e-04, 4.67706729e-04,\n",
       "       4.60260084e-04, 4.59439099e-04, 4.48533564e-04, 4.41331755e-04,\n",
       "       4.36781060e-04, 4.27687796e-04, 4.21681488e-04, 4.15455995e-04,\n",
       "       4.06890758e-04, 4.06450119e-04, 3.97403121e-04, 3.85398960e-04,\n",
       "       3.83790344e-04, 3.78703940e-04, 3.67852355e-04, 3.61876886e-04,\n",
       "       3.53092872e-04, 3.47018966e-04, 3.44820054e-04, 3.34460402e-04,\n",
       "       3.32033178e-04, 3.25504835e-04, 3.12713242e-04, 3.01951266e-04,\n",
       "       2.87644796e-04, 2.72970621e-04, 2.66897947e-04, 2.58702942e-04,\n",
       "       2.53193752e-04, 2.45723451e-04, 2.40693435e-04, 2.37548509e-04,\n",
       "       2.27915316e-04, 2.25434779e-04, 2.20973724e-04, 2.14400853e-04,\n",
       "       2.07930759e-04, 2.04523771e-04, 1.97596126e-04, 1.94959883e-04,\n",
       "       1.88072371e-04, 1.81410189e-04, 1.79783786e-04, 1.74536521e-04,\n",
       "       1.69050152e-04, 1.67211851e-04, 1.63419232e-04, 1.55803526e-04,\n",
       "       1.55018287e-04, 1.48301137e-04, 1.46270887e-04, 1.43324346e-04,\n",
       "       1.38115711e-04, 1.35115778e-04, 1.31316569e-04, 1.24411375e-04,\n",
       "       1.23126046e-04, 1.20036531e-04, 1.18231149e-04, 1.14815188e-04,\n",
       "       1.11205755e-04, 1.07825119e-04, 1.05026060e-04, 1.02731944e-04,\n",
       "       9.89382110e-05, 9.84757528e-05, 9.67133751e-05, 9.50891340e-05,\n",
       "       9.27563003e-05, 9.08351608e-05, 9.00257278e-05, 8.92219631e-05,\n",
       "       8.84580858e-05, 8.75710691e-05, 8.48217118e-05, 8.19213456e-05,\n",
       "       8.16694521e-05, 8.01338935e-05, 7.93155476e-05, 7.77516254e-05,\n",
       "       7.61916604e-05, 7.50207661e-05, 7.37833941e-05, 7.17101529e-05,\n",
       "       7.09200467e-05, 6.96773752e-05, 6.87731327e-05, 6.79043864e-05,\n",
       "       6.65127193e-05, 6.50709464e-05, 6.46595079e-05, 6.24069803e-05,\n",
       "       6.15980954e-05, 6.07418453e-05, 5.94303245e-05, 5.89740665e-05,\n",
       "       5.84108187e-05, 5.74988893e-05, 5.68755166e-05, 5.59835739e-05,\n",
       "       5.44701900e-05, 5.30947988e-05, 5.29347204e-05, 5.15234637e-05,\n",
       "       5.11979509e-05, 4.97091935e-05, 4.85786340e-05, 4.77978607e-05,\n",
       "       4.68547845e-05, 4.60470917e-05, 4.51655610e-05, 4.40521446e-05,\n",
       "       4.30004068e-05, 4.24471372e-05, 4.18055254e-05, 4.05022489e-05,\n",
       "       4.04117355e-05, 3.98799638e-05, 3.86221709e-05, 3.85242643e-05,\n",
       "       3.79308315e-05, 3.74843914e-05, 3.62392572e-05, 3.55493919e-05,\n",
       "       3.48603474e-05, 3.45227891e-05, 3.34348239e-05, 3.30263361e-05,\n",
       "       3.24882840e-05, 3.19591221e-05, 3.16765506e-05, 3.09128449e-05,\n",
       "       3.03738355e-05, 2.93091104e-05, 2.91123255e-05, 2.87539515e-05,\n",
       "       2.79065340e-05, 2.77300299e-05, 2.75186874e-05, 2.67588085e-05,\n",
       "       2.61616772e-05, 2.59289385e-05, 2.56162790e-05, 2.51460920e-05,\n",
       "       2.46083680e-05, 2.42512831e-05, 2.40715065e-05, 2.38569634e-05,\n",
       "       2.29586961e-05, 2.28618583e-05, 2.24754279e-05, 2.23647662e-05,\n",
       "       2.18392374e-05, 2.15026711e-05, 2.14583114e-05, 2.08174494e-05,\n",
       "       2.05800369e-05, 2.00891723e-05, 1.96595039e-05, 1.94991022e-05,\n",
       "       1.92448825e-05, 1.88617677e-05, 1.86326463e-05, 1.84793954e-05,\n",
       "       1.81916547e-05, 1.79248832e-05, 1.76083450e-05, 1.72070169e-05,\n",
       "       1.69909615e-05, 1.63526396e-05, 1.63136650e-05, 1.60294153e-05,\n",
       "       1.58270326e-05, 1.57724226e-05, 1.54316822e-05, 1.51969075e-05,\n",
       "       1.50913077e-05, 1.47828056e-05, 1.46655482e-05, 1.42165212e-05,\n",
       "       1.41834638e-05, 1.36341891e-05, 1.33555279e-05, 1.29900312e-05,\n",
       "       1.29294117e-05, 1.25353505e-05, 1.23219392e-05, 1.21750066e-05,\n",
       "       1.18558670e-05, 1.15352058e-05, 1.13404171e-05, 1.10511081e-05,\n",
       "       1.09611028e-05, 1.05344856e-05, 1.04190435e-05, 1.02255099e-05,\n",
       "       9.80868367e-06, 9.67308269e-06, 9.51930478e-06, 9.29122719e-06,\n",
       "       9.02276779e-06, 8.73028356e-06, 8.36564965e-06, 8.17181743e-06,\n",
       "       8.12938677e-06, 7.86436856e-06, 7.63991585e-06, 7.47619765e-06,\n",
       "       7.15305339e-06, 6.89781419e-06, 6.71676782e-06, 6.53175676e-06,\n",
       "       6.49841642e-06, 6.20322405e-06, 5.95560300e-06, 5.83240146e-06,\n",
       "       5.75269401e-06, 5.42711375e-06, 5.32137808e-06, 5.30940411e-06,\n",
       "       5.03939665e-06, 4.99979634e-06, 4.71172562e-06, 4.62470006e-06,\n",
       "       4.48539878e-06, 4.36501357e-06, 4.12731435e-06, 4.09766909e-06,\n",
       "       3.99385402e-06, 3.92766592e-06, 3.83063607e-06, 3.74087684e-06,\n",
       "       3.60509941e-06, 3.49981402e-06, 3.47251473e-06, 3.27496078e-06,\n",
       "       3.14252481e-06, 3.07268704e-06, 2.95945138e-06, 2.68848863e-06,\n",
       "       2.60132203e-06, 2.57382803e-06, 2.50143159e-06, 2.28328181e-06,\n",
       "       2.21319686e-06, 2.13254979e-06, 2.05755186e-06, 2.04451725e-06,\n",
       "       2.00508444e-06, 1.94260578e-06, 1.86940434e-06, 1.63735778e-06,\n",
       "       1.57819013e-06, 1.51699685e-06, 1.46239158e-06, 1.35337833e-06,\n",
       "       1.31821483e-06, 1.30295936e-06, 1.24207259e-06, 1.17279554e-06,\n",
       "       1.12336459e-06, 1.07387248e-06, 1.01031825e-06, 9.64850615e-07,\n",
       "       9.23556380e-07, 8.85112556e-07, 8.63070817e-07, 8.15489040e-07,\n",
       "       7.82447301e-07, 7.48977419e-07, 7.22031073e-07, 7.08413977e-07,\n",
       "       6.80614867e-07, 6.72598390e-07, 6.38226074e-07, 6.17041447e-07,\n",
       "       5.97104084e-07, 5.79125379e-07, 5.63867514e-07, 5.39881906e-07,\n",
       "       5.24777372e-07, 4.87378647e-07, 4.79404306e-07, 4.63103988e-07,\n",
       "       4.24362867e-07, 4.08820575e-07, 3.83888013e-07, 3.68680552e-07,\n",
       "       3.59219260e-07, 3.55685624e-07, 3.48884946e-07, 3.09019991e-07,\n",
       "       2.97699315e-07, 2.72934413e-07, 2.63431007e-07, 2.56298661e-07,\n",
       "       2.28036183e-07, 2.06346675e-07, 2.02590071e-07, 1.44899382e-07,\n",
       "       7.16208729e-08, 4.57618735e-08, 4.10139604e-08, 3.47481223e-08,\n",
       "       3.36317918e-08, 2.70497747e-08, 2.63603511e-08, 2.25947688e-08,\n",
       "       2.14570729e-08, 2.04545894e-08, 1.73566486e-08, 1.64610429e-08,\n",
       "       1.15495077e-08, 1.13783362e-08, 1.01692960e-08, 9.21043325e-09,\n",
       "       7.23201302e-09, 6.70512504e-09, 6.00532166e-09, 5.51051430e-09,\n",
       "       4.12412079e-09, 2.41318941e-10, 1.44663588e-10, 1.02460672e-10,\n",
       "       3.71018258e-12, 1.07610936e-12, 2.78989436e-13, 3.05247240e-18,\n",
       "       2.84787726e-18, 2.61307581e-18, 2.19193517e-18, 1.84669252e-18,\n",
       "       1.79607344e-18, 1.70659488e-18, 1.68129931e-18, 1.63504898e-18,\n",
       "       1.52513367e-18, 1.38296837e-18, 1.24391607e-18, 1.16028404e-18,\n",
       "       1.13889776e-18, 1.12634393e-18, 1.06911601e-18, 1.02001092e-18,\n",
       "       8.80502596e-19, 8.66907519e-19, 8.54605653e-19, 8.12974320e-19,\n",
       "       8.04193403e-19, 7.92399148e-19, 7.64536284e-19, 7.40636185e-19,\n",
       "       7.10589055e-19, 6.83586948e-19, 6.33116116e-19, 6.12793583e-19,\n",
       "       5.99339063e-19, 5.80085478e-19, 5.39162049e-19, 5.00780000e-19,\n",
       "       4.69742377e-19, 4.29826419e-19, 4.17739603e-19, 4.14901437e-19,\n",
       "       3.94692648e-19, 3.85091745e-19, 3.67668383e-19, 3.55289764e-19,\n",
       "       3.51602625e-19, 3.44292312e-19, 3.38017150e-19, 3.32114748e-19,\n",
       "       3.24009798e-19, 3.22406286e-19, 3.06759850e-19, 3.00682465e-19,\n",
       "       2.93167442e-19, 2.88118914e-19, 2.77005280e-19, 2.68344451e-19,\n",
       "       2.60054640e-19, 2.54365219e-19, 2.51983275e-19, 2.44437762e-19,\n",
       "       2.42489746e-19, 2.33287260e-19, 2.25666250e-19, 2.09227148e-19,\n",
       "       1.92966773e-19, 1.90103128e-19, 1.79962196e-19, 1.74246737e-19,\n",
       "       1.45514933e-19, 1.36925064e-19, 9.83501050e-20, 7.21768851e-20,\n",
       "       5.66223401e-20, 3.05427502e-33, 3.05427502e-33, 3.05427502e-33,\n",
       "       3.05427502e-33, 3.05427502e-33, 3.05427502e-33, 3.05427502e-33,\n",
       "       3.05427502e-33, 3.05427502e-33, 3.05427502e-33, 3.05427502e-33,\n",
       "       3.05427502e-33, 3.05427502e-33, 3.05427502e-33, 3.05427502e-33,\n",
       "       3.05427502e-33, 3.05427502e-33, 3.05427502e-33, 3.05427502e-33,\n",
       "       5.43787857e-35, 1.02715708e-35])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # create model\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units=64,kernel_initializer='uniform',activation='relu',input_shape=(11,)))\n",
    "\n",
    "    model.add(keras.layers.Dense(units=128,kernel_initializer='uniform',activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(units=64,kernel_initializer='uniform',activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(units=6,kernel_initializer='uniform',activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-aa43e0b8699b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Build the Keras model (already compiled)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Train the model (in silent mode, verbose=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_part\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_part\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-fa88024c8759>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_val = len(X_train) // k\n",
    "num_epochs = 22\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    X_val = X_train[i * num_val: (i + 1) * num_val]\n",
    "    Y_val = y_train[i * num_val: (i + 1) * num_val]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    X_train_part = np.concatenate(\n",
    "        [X_train[:i * num_val],\n",
    "         X_train[(i + 1) * num_val:]],\n",
    "        axis=0)\n",
    "    Y_train_part = np.concatenate(\n",
    "        [y_train[:i * num_val],\n",
    "         y_train[(i + 1) * num_val:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(X_train_part, Y_train_part,epochs=num_epochs,  batch_size=256 , verbose=0)\n",
    "    # Evaluate the model on the validation data \n",
    "    val_loss, val_acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    all_scores.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubicomp_Lab\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Ubicomp_Lab\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
